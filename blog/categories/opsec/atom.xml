<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: OPSEC | Hacker OPSEC]]></title>
  <link href="http://grugq.github.com/blog/categories/opsec/atom.xml" rel="self"/>
  <link href="http://grugq.github.com/"/>
  <updated>2013-11-19T01:05:35+07:00</updated>
  <id>http://grugq.github.com/</id>
  <author>
    <name><![CDATA[the grugq]]></name>
    <email><![CDATA[the.grugq@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[required reading]]></title>
    <link href="http://grugq.github.com/blog/2013/11/06/required-reading/"/>
    <updated>2013-11-06T07:23:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/11/06/required-reading</id>
    <content type="html"><![CDATA[<p>This is a short list of articles and papers that you absolutely must read if you want to understand OPSEC.</p>

<ul>
<li><p><a href="http://repository.library.georgetown.edu/bitstream/handle/10822/553096/mobleyBlake.pdf?sequence=1">Terrorist Group Counterintelligence</a> :: This is the thesis which later became the book <a href="http://www.amazon.com/Terrorism-Counterintelligence-Terrorist-Detection-Irregular/dp/0231158769">Terrorism and Counterintelligence</a>. Read at least one of them (the thesis is free).</p></li>
<li><p><a href="http://www.oss.net/dynamaster/file_archive/100102/0a947a77d762061cc87ec541c2d2dcc7/2010-01-02%20Dulles%20on%20Tradecraft%20via%20Srodes.pdf">Allen Dulle's 73 Rules of Spycraft</a> :: This is the handbook of how to live and operate securely. It is 50 years old and it has aged remarkably well. Read it. Study it. This will be on the test.</p></li>
<li><p><a href="http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA505161">Clandestine Cellular Networks</a> :: This paper deals primarily with the lessons learned from fighting insurgents, but it is extremely valuable as a handbook on tradecraft. I previously posted just the tradecraft <a href="http://grugq.github.io/resources/tradecraft-howto.pdf">chapter</a> for people who don't want to slog through all of it. I suggest reading all of it.</p></li>
<li><p><a href="http://igcc3.ucsd.edu/research/security/DACOR/presentations/Shapiro.pdf">The Terrorists Challenge: Security, Efficiency, Control</a> :: This paper examines the primary trade offs that need to be made when operating a covert organisation. If you have multiple people working in secret, managing them and their work requires making tradeoffs between security, efficiency and control. This paper will help you to understand those tradeoffs.</p></li>
</ul>


<h3>Optional</h3>

<ul>
<li><a href="http://www.tandfonline.com/doi/pdf/10.1080/10576100802670803">A Study of al Quaeda's use of Intelligence and Counterintelligence</a> :: This pulls a lot of the information above into a single case study of a covert (terrorist) organisation planning and conducting an operation. Anything else you can lay your hands on by the author I recommend as well.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Morris Worm OPSEC lessons]]></title>
    <link href="http://grugq.github.com/blog/2013/11/06/morris-worm-opsec-lessons/"/>
    <updated>2013-11-06T04:08:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/11/06/morris-worm-opsec-lessons</id>
    <content type="html"><![CDATA[<h2>25th Anniversary of STFU about your computer crimes</h2>

<p>Reading <a href="http://www.washingtonpost.com/blogs/the-switch/wp/2013/11/05/heres-what-the-morris-worm-prosecutor-thinks-about-aaron-swartz/">this interview</a> with the prosecutor of Robert Morris Jr about the Morris Worm there are a few cool OPSEC lessons we can learn.</p>

<h2>How was Morris caught?</h2>

<blockquote><p>One way was with computer forensics. Tracing back the source of the worm. The second way was one of Morris's friends told The New York Times in response to some articles that John Markoff was writing he inadvertently gave his initials.</p></blockquote>

<p>There were a couple of ways that he was discovered. The first was the forensic analysis of the worm itself, and tracing that back to the original infection point. This sort of evidence shows where to look (the original infection), but it does not provide enough information to successfully prosecute. It is circumstantial so far, and given some careful sanitisation of the original box, it would be a very hard case to prove.</p>

<p>The far more damaging way that Morris was caught was via an OSINT case officer doing HUMINT collection (a reporter interviewing people about the worm). The journo managed to elicit information about the worm's author (his initials). This is the sort of extremely damaging information leakage that happens when there is poor OPSEC. There was no anti-interrogation training provided to the members of the Morris cell (i.e. all his friends who knew about the development of the worm).</p>

<h2>Deny everything. Admit nothing. Or, you know, not.</h2>

<blockquote><p>he did testify that he wrote the worm. He came in and testified, "I did it, and I'm sorry." I turned to my co-counsel and asked, "Should I prove he didn't do it or he's not sorry?"</p></blockquote>

<p>When the prosecution has to prove that you committed a felonious act, it is a lot easier for them when you <strong>confess</strong> on the stand. I can't second guess the decisions of Morris' legal counsel, but unless you are instructed to do so by your lawyer: STFU.</p>

<h2>The Morris Cell and "Need to know"</h2>

<blockquote><p>We talked to his friends. His friends were witnesses for us. They didn't have a choice.
There was a core group. ...one of the meetings where Robert Morris was discussing the worm occurred at a Legal Seafood in Kendall Square...
He talked about how it was developed, how it worked, what vulnerabilities it exploited. At one point he was at a meeting back at Harvard, he got so excited that he literally jumped up on a table pacing back and forth on the table explaining how it worked...</p></blockquote>

<p>The close friends of Robert Morris, the Morris Cell, were fully briefed on all aspects of the worm. Its capabilities, its functionality, and its author's real identity. None of the other members of the cell were actively exposed to the risks of the operation. They had no "need to know".</p>

<p>This failure to STFU, to properly compartment the design and development of the worm, was a key factor leading to his capture and prosecution. Fortunately, things worked out well for him, in the long run.</p>

<h2>How to evaluate "Need to know"</h2>

<p>The rule of thumb is: <em>if someone is actively sharing the risk, they have a need to know</em>. This need to know is, of course, restricted to only those aspects of the operation in which they are actively involved.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OPSEC isn't security through obscurity]]></title>
    <link href="http://grugq.github.com/blog/2013/11/04/opsec-isnt-security-through-obscurity/"/>
    <updated>2013-11-04T01:04:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/11/04/opsec-isnt-security-through-obscurity</id>
    <content type="html"><![CDATA[<h2>OPSEC revisited</h2>

<blockquote><p>The goal of OPSEC is to control information about your capabilities and intentions to keep them from being exploited by your adversary.</p></blockquote>

<p>In typical hacker fashion, the term OPSEC has come to mean more than just information about capabilities and intentions, but also personal information about the yourself.</p>

<h2>Kerckoff's Principle and OPSEC</h2>

<p>A common source for the idea that "security through obscurity is bad" is <a href="http://en.wikipedia.org/wiki/Kerckhoffs%27_principle">Kerckoffs' principle</a> which states that: <code>A cryptosystem should be secure even if everything about the system, except the key, is public knowledge</code>. OPSEC as a system of security is sometimes confused with "security through obscurity". This is not the case. Such thinking reflects a confusion of both the problem with opaque security systems and the foundations of OPSEC.</p>

<h2>OPSEC is a System</h2>

<p>The way to clear this confusion, I believe, is to point out that OPSEC is a security system, not any one specific practice. The system itself is open source, in that we know how and why the various techniques and practices work. For example, the tradecraft technique of a <a href="http://en.wikipedia.org/wiki/Dead_drop">dead drop</a> is public knowledge. The security of a dead drop is not that no one knows how they work, but rather the adversary does not know <strong>where</strong> a specific dead drop is locate, nor <strong>when</strong> that dead drop is being serviced (loaded or unload). That information, primarily the location of that dead drop, is the <strong>secret key</strong> to the dead drop security system. This information is what must remain secret for the dead drop to remain secure.</p>

<h2>Why OPSEC Works</h2>

<p>So OPSEC as a system of security does not violate Kerckoff's principle, and is not "security through obscurity". The specifics of any one application of OPSEC techniques provide security, but those are analogous to the private key to the system. If they are compromised, then security they provide will be be compromised.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Observations on OPSEC]]></title>
    <link href="http://grugq.github.com/blog/2013/10/21/observations-on-opsec/"/>
    <updated>2013-10-21T19:03:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/10/21/observations-on-opsec</id>
    <content type="html"><![CDATA[<p>Briefly, I would like to highlight some important considerations for good OPSEC. Firstly, OPSEC is a mode of operating, not a tool or a collection of tools. Secondly, OPSEC comes at a cost, and a significant part of that cost is efficiency. OPSEC is slow. Finally, maintaining a strong security posture (i.e. “good OPSEC”) for long periods of time is very stressful, even for professionally trained espionage officers.</p>

<p>Learning good OPSEC requires internalizing the behavioural changes required to continually maintain a strong security posture. The operational activities have to become habit, because the small things matter, and every careless mistake can compromise security. The only way to develop good OPSEC habits, good security hygiene, is to practice. Make the foolish beginners mistakes during a practice session, rather than in the field. Two relevant sayings:</p>

<ul>
<li>Amateurs practice until they get it right, professionals practice until they can’t get it wrong</li>
<li>The more you sweat in peace, the less you bleed in war</li>
</ul>


<p>After developing good security hygiene habits, the second most difficult thing about good OPSEC is learning patience. Increased OPSEC security comes at the cost of efficiency, primarily in communication time-frames. The OPSEC mechanisms that must be in place to reduce the risks during communication add latency. As a result, communication takes significantly longer and is less reliable. Obviously, this is more of an issue with time sensitive operations than those that have more generous deadlines.</p>

<p>The single greatest security risk is communication between operatives. Clandestine agencies, such as the CIA, MI6, DGSE, etc. will work incredibly hard to minimize the risks surrounding communication with their recruited agents. In the simplest form, this involves a 2-4 hour “surveillance detection route” (SDR) to see if they are “in the black” before they perform any operational activity. This is on top of the hours of planning for the operation itself (note: these are minimums, operations requiring high security might take weeks or months of planning, and 12 hour SDRs).</p>

<p>The technology that exists to facilitate information security, e.g. encryption, is important, but it is not sufficient or even the starting point for robust OPSEC. By all means, learn to use encryption software correctly and in a properly secure fashion. However, it is more important to compartment sensitive activities and structure your operational environment for impact containment than
install use particular software.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Silk Road Security]]></title>
    <link href="http://grugq.github.com/blog/2013/10/10/silk-road-security/"/>
    <updated>2013-10-10T18:53:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/10/10/silk-road-security</id>
    <content type="html"><![CDATA[<h2>Counterintelligence Lessons for Drug Dealers</h2>

<p><strong>NOTE</strong> Events have overtaken my slow writing speed. This post was in the works
before the Silk Road bust in September 2013. I'm uploading it anyway because it
has some useful information, however there seems little point in finish it now.</p>

<p>The dealers on Silk Road ship a large amount of illegal products around the world, and it is clear that they're successful at it. However, the US Postal service has been aware that drug dealers user their service for shipping illegal substances and has developed guidelines for determining suspect packages efficiently. Unfortunately for them, those guidelines have leaked and this allows someone abusing the US mail as an illicit distribution channel to evade the USP's checks.</p>

<h2>Suspicious Post Guidelines</h2>

<p>The actual <a href="http://teknopolitik.tumblr.com/post/48178417204/fbi-law-enforcement-bulletin-via-findarticles">guidelines for suspicious packages</a> list a number of major indicators that the inspectors look for. This guide is somewhat outdated, and a <a href="http://www.orlandocriminaldefenseattorneyblog.com/2012/05/drug-trafficking-via-express-m.html">revised version</a> has also be leaked. In both cases, the <strong>triggers</strong> and the reasoning behind them are similar.</p>

<h3>FBI Profiling Criteria</h3>

<ol>
<li>Heavy taping along the seams;</li>
<li>poor preparation for mailing;</li>
<li>uneven weight distribution;</li>
<li>apparent package reuse; and</li>
<li>labels that are handwritten, contain misspellings, originate from a drug-source State, indicate person-to-person not business-to-individual mail, have a return zip code that does not match the accepting post office zip code, a fictitious return address, names of senders or recipients with features in common (John Smith, e.g.) and having no connection to either address</li>
</ol>


<h3>Drug Mail Profile</h3>

<ol>
<li>the use of Express Mail,

<ul>
<li>Express Mail is primarily used by businesses for document delivery.</li>
</ul>
</li>
<li>the weight of the package,

<ul>
<li>drug traffickers are mailing approximately one kilo of cocaine per package, plus some dummy weights</li>
</ul>
</li>
<li>the package is sent from Puerto Rico, a known drug source location,</li>
<li>the package was mailed from a post office address outside of the zip code on the return address,</li>
<li>an Accurint check reveals that no one by the sender's name lived at the return address,

<ul>
<li>Police will also check Google and Facebook to get more information</li>
</ul>
</li>
<li>the package is heavily taped at all seams

<ul>
<li>heavy taping may or may not help evade detection by drug sniffing dogs--but we know one thing for sure--it certainly helps draw police attention to the package!</li>
</ul>
</li>
<li>the label is handwritten

<ul>
<li>Since most Express Mail is business-to-business, or business-to-client, labels that aren't typed are suspect</li>
</ul>
</li>
</ol>


<h3>Collated</h3>

<p>Anything that looks like someone is sending slightly over an even metric weight of <em>something</em>, from a known suspect location, to another person, in an old heavily taped package with a fake return address. Sounds like bad tradecraft.</p>

<ol>
<li>Suspicious packaging

<ul>
<li>Heavy taping</li>
<li>Package reuse</li>
</ul>
</li>
<li>Not business mail

<ul>
<li>No printed label</li>
<li>Clearly not documents</li>
<li>Individual to individual</li>
</ul>
</li>
<li>Known suspicious origin

<ul>
<li>Occasionally specific post offices</li>
<li>Specific countries (Puerto Rico)</li>
</ul>
</li>
<li>Flimsy "return address" cover

<ul>
<li>Fake name</li>
<li>Mismatched name + address</li>
<li>Mismatched address + zipcode</li>
</ul>
</li>
</ol>


<p>Main points to take away:</p>

<ul>
<li>drug packages appear different from normal mail</li>
<li>many factors are contribute to creating a plausible cover/alias.</li>
<li>The packaging of a drug shipment provides a cover, which needs to be backstopped.</li>
</ul>


<p>Don't make shit up, do your research and steal an identity with a real address.</p>

<h2>Backstop your cover</h2>

<p>When creating a cover, make sure it is as fully fleshed out as possible. This means developing supporting evidence to bolster the validity of the cover. In intelligence lingo, this is called backstopping.</p>

<p>A backstopped cover is one where checks to verify the authenticity of the cover story are verifiable. For example, if the cover story includes a name, there are matching identity documents; if there is an phone number, it connects to someone who will substantiate the cover story; if there is an address, it exists. The old Soviet illegals used to spend years developing their cover and backstopping them. They'd live for a few years in a country they claimed to be immigrating from, so they would have the memories, experience and verifiable evidence that they were from there.</p>

<p>If you are going to use a cover (you probably should), then put in the effort to create a backstop. The complexity and depth of that backstop are dependant on how deeply the cover will be investigated. Remember though, it is better to have too much, than not enough...</p>
]]></content>
  </entry>
  
</feed>
