<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: OPSEC | Hacker OPSEC]]></title>
  <link href="http://grugq.github.com/blog/categories/opsec/atom.xml" rel="self"/>
  <link href="http://grugq.github.com/"/>
  <updated>2014-05-19T18:38:51+07:00</updated>
  <id>http://grugq.github.com/</id>
  <author>
    <name><![CDATA[the grugq]]></name>
    <email><![CDATA[the.grugq@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[New York's Finest OPSEC]]></title>
    <link href="http://grugq.github.com/blog/2014/02/13/new-yorks-finest-opsec/"/>
    <updated>2014-02-13T19:35:00+07:00</updated>
    <id>http://grugq.github.com/blog/2014/02/13/new-yorks-finest-opsec</id>
    <content type="html"><![CDATA[<h2>NYPD Social Media Investigation OPSEC</h2>

<p>The NYPD created an operations formula for conducting undercover investigations on social media. The <a href="http://publicintelligence.net/nypd-social-network-investigations/">procedural document</a> reveals the operational security for these investigations. The security is founded on the use of an "online alias" (the officer's undercover account) and strict compartmentation. Given the capabilities of the adversaries that the NYPD faces this is probably sufficient security.</p>

<p>It is a fascinating glimpse into the operational process of an investigation. Definitely worth reading to get a sense of what the police face when conducting an online investigation (hint: paperwork).</p>

<h2>Core NYPD OPSEC</h2>

<p>Fundamentally this is basic operational security grounded on compartmentation. The use of dedicated hardware, and pseudononymous internet access, allows the officer to create and operate an online undercover account without any links to the NYPD. The basic security precautions are designed to protect the officer's laptop from being compromised. A compromised laptop could enable the adversary to conduct a counterintelligence investigation.</p>

<ul>
<li>Compartmentation:

<ul>
<li>Use dedicated hardward and pseudononymous internet connection (laptop + "aircard")</li>
<li>Avoid accounts, usernames, passwords associated with NYPD</li>
<li>Avoid personal accounts and internet access</li>
</ul>
</li>
<li>Basic Computer Security:

<ul>
<li>Delete "spam"</li>
<li>Don't open attachments</li>
<li>Exercise caution when clicking on links</li>
</ul>
</li>
</ul>


<p>This is very basic stuff, but should be more than sufficient against the adversaries that the NYPD pursues. These adversaries should not have access to any of the records of the phone company supplying the internet access.</p>

<h2>Primary Document</h2>

<p>Here is the information that is required to create the undercover account:</p>

<blockquote><ol type="a">
<li> Username (online alias)</li>
<li> Identifiers and pedigree to be utilized for the online alias, such as email address, username and date of birth.</li>
<li> Do not include password(s) for online alias and ensure password(s) are secured at all times.</li>
<li> Indicate whether there is a need to requisition a Department laptop with aircard.</li>
<li>Review photograph to be used in conjunction with online alias, if applicable.</li>
<li> Consider the purpose for which the photograph is being used and the source of the photograph.</li>
</ol>
</blockquote>

<p>Here is the full section dealing with operational security:</p>

<blockquote><h1>Operational Considerations</h1>

<p>When a member of the service accesses any social media site using a Department network connection, there is a risk that the Department can be identified as the user of the social media. Given this possibility of identification during an investigation, members of the service should be aware that Department issued laptops with aircards have been configured to avoid detection and are available from the Management Information Systems Division (MISD). A confidential Internet connection (e.g., Department laptop with aircard) will aid in maintaining confidentiality during an investigation. Members who require a laptop with aircard to complete the investigation shall contact MISD Help Desk, upon APPROVAL of investigation, and provide required information.</p>

<p>In addition to using a Department laptop with aircard, members of the service are urged to take the following precautionary measures:</p>

<ol type="a">
<li>Avoid the use of a username or password that can be traced back to the member of the service or the Department;</li>
<li>Exercise caution when clicking on links in tweets, posts, and online advertisements;</li>
<li>Delete “spam” email without opening the email; and</li>
<li>Never open attachments to email unless the sender is known to the member of the service.</li>
</ol>


<p>Furthermore, recognizing the ease with which information can be gathered from minimal effort from an Internet search, the Department advises members against the use of personal, family, or other non-Department Internet accounts or ISP access for Department business. Such access creates the possibility that the member’s identity may be exposed to others through simple search and counter-surveillance techniques.</p></blockquote>

<h2>Conclusions</h2>

<p>Undercover operations online rely on very basic operational security. Primarily compartmentation and reviews to ensure that the account isn't going to be associated with the NYPD.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Fistful of Surveillance]]></title>
    <link href="http://grugq.github.com/blog/2014/02/10/a-fistful-of-surveillance/"/>
    <updated>2014-02-10T19:11:00+07:00</updated>
    <id>http://grugq.github.com/blog/2014/02/10/a-fistful-of-surveillance</id>
    <content type="html"><![CDATA[<p>The publication of <a href="https://firstlook.org/theintercept/article/2014/02/10/the-nsas-secret-role/">this piece</a> at <a href="https://firstlook.org/theintercept/">The Intercept</a> about NSA targeting via mobile phones prompted me to release this collection of notes. Some quotes and statements in the article wrongly promote the idea that the SIM card is the only unique identifier in a mobile phone. I've enumerated the identifiers that exist, and they go far beyond the SIM card. At a minimum the physical identifiers of a mobile phone are the <a href="http://en.wikipedia.org/wiki/International_mobile_subscriber_identity">IMSI</a> and the <a href="http://en.wikipedia.org/wiki/International_Mobile_Station_Equipment_Identity">IMEI</a>, that is the SIM card and the mobile phone hardware itself.</p>

<p>This is a short collection of notes I've put together on how you can be identified via your mobile phone. If you want to securely use a mobile phone, you'll need to use a burner. This is non-trivial. <a href="http://b3rn3d.herokuapp.com/blog/2014/01/22/burner-phone-best-practices/">Here's a good guide</a>.</p>

<h2>Clandestine Mobile Phone Use</h2>

<p>Mobile phones should primarily be used for signalling, rather than for actually communicating operational information. Remember the golden rule of telephone conversations:</p>

<ul>
<li>keep it short</li>
<li>keep it simple</li>
<li>stick to your cover</li>
</ul>


<h2>Identifiers</h2>

<ul>
<li><strong>Location</strong>

<ul>
<li>Specific location (home, place of work, etc.)</li>
<li><a href="http://www.nature.com/srep/2013/130325/srep01376/full/srep01376.html">Mobility pattern</a> (from home, via commuter route, to work) -- very unique, 4 loc's will identify 90%</li>
<li>Paired mobility pattern with a known device (known as "mirroring", when two devices or more devices travel together)</li>
</ul>
</li>
<li><strong>Network</strong>

<ul>
<li>numbers dialed (who you call)</li>
<li>calls received (who calls you)</li>
<li>calling pattern (numbers dialed, for how long, how frequently)</li>
</ul>
</li>
<li><strong>Physical</strong>

<ul>
<li>IMEI (mobile phone device ID)</li>
<li>IMSI (mobile phone telco subscriber ID)</li>
</ul>
</li>
<li><strong>Content</strong>

<ul>
<li>Identifiers, e.g. names, locations</li>
<li>Voice fingerprinting</li>
<li>Keywords</li>
</ul>
</li>
</ul>


<h2>Mitigations</h2>

<h3>Turn it OFF, for real.</h3>

<p>Know how to turn the phone to a completely off state. This means removing the battery, taking out the SIM card and placing in a shielded bag (if possible). This <strong>really off</strong> state is how you store and transport the phone when not in use.</p>

<p>A note on storage: it should not be at your house or anywhere that is directly linked to you.</p>

<h3>Take a hike, buster</h3>

<p>Where you use the phone is itself very important. Never use it at locations which are associated with you, that means never at home, never at the office/work, never at a friend's house. Never have the phone in an <strong>ON</strong> state at locations that are associated with you, or your immediate social network. Never.</p>

<p>Do not turn the phone in the same location as a phone associated with you. Make sure that your real phone is somewhere else, but not in an <strong>OFF</strong> state if possible. You don't want the disappearance of one phone from the network to coincide with the appearance of another. Paired events are indicators of relation, and you want to avoid those as much as possible. You also want you regular phone to appear with a typical usage pattern, which means keeping it on as you normally would.</p>

<h3>Contamination, avoid it</h3>

<p>Never use different phones from the same location.</p>

<p>Never carry phones for different compartments together (keep them turned off, batteries out)</p>

<p>Never carry phones turned on over the same routes you normally take. Avoid patterns and predictability.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Codes, What Are They Good For?]]></title>
    <link href="http://grugq.github.com/blog/2013/12/21/codes-what-are-they-good-for/"/>
    <updated>2013-12-21T20:00:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/12/21/codes-what-are-they-good-for</id>
    <content type="html"><![CDATA[<h2>What is a Secure Communication?</h2>

<p>The goals of secure communications are the following. Some of these are surprisingly difficult to achieve:</p>

<ol>
<li>Make the <strong>content</strong> of a message <strong>unreadable</strong> to parties other than the intended one(s)</li>
<li>Make the <strong>meaning</strong> of a message <strong>inaccessible</strong> to parties other than the intended one(s)</li>
<li>Avoid <strong>traffic analysis</strong> — don’t let other parties know that a connection exists between the communicating parties</li>
<li>Avoid <strong>knowledge of the communication</strong> — don’t let other parties know the communication channel or pathway exists</li>
</ol>


<p>The first and second objectives can be accomplished using some combination of <strong>cryptography</strong> and <strong>coding</strong>. Unfortunately, this is the easy part. The more
complicated and difficult component of a secure communications infrastructure is
achieving the third and fourth objectives. For now, however, I will focus only
on the first two issues: protecting content, and meaning.</p>

<p>First lets define our terms so we can discuss the subject with clarity:</p>

<ul>
<li><strong>Cryptography</strong> systems that use transformation processes to turn <em>signal into noise</em>, by obscuring the symbols used for communication</li>
<li><strong>Coding</strong> systems that substitute or alter meaning, and thus hide the real message</li>
</ul>


<h2>The Eagle Has Landed</h2>

<p>Codes are extremely useful mechanisms for sending small messages, although as they are <em>plain text</em> their hidden mean can be revealed once the <em>key</em> is cracked. Another issue with codes is that they are inflexible, compared to a cipher system. Coding requires pre-arranged mappings of meanings (what symbols or words translate to what), or at least pre-arranged mechanisms to derive the mappings (e.g., book codes).</p>

<p>To be effective, a code must maintain <strong>proper grammar</strong>, be <strong>consistent</strong>, and fit a <strong>plausible</strong> pretext. If it fits these requirements, and is used appropriately (briefly, consistently, with <a href="http://www.stratfor.com/weekly/20100616_watching_watchers"><em>cover for action</em></a>) then a code system is an excellent choice for simple signalling purposes.</p>

<h3>Doing It Right</h3>

<p>During World War II the BBC cooperated with the intelligence services to send
open code signals to operatives in the occupied territories. These signals were
prearranged with the operatives, and then sent out at two scheduled times. This
signalling channel was used exclusively for indicating whether an operation was
going to take place.</p>

<p>The BBC would broadcast the signal for the first time at 1930, and then confirm
the signal at 2115. If the operation had been canceled before the second scheduled
signal window, the code phrase would not be repeated.</p>

<p>During the early phase of the war, the code system was slightly more complex.
There would be a positive code, and a negative code, for example: "Jeanne sends
her greetings" might be a "go code", and "Jeanne says hello" might be the "abort
code". Later this was simplified to just the positive code (a tradition that,
apparently, the CIA still follows).</p>

<h3>Doing It Wrong</h3>

<p>There are problems when codes are used inconsistently. For example, some <a href="http://www.wmob.com/cast.html">mafia codes</a> used oblique references to the boss as "aunt", or "Aunt Julia". This was very ineffective when the mafioso suffered pronoun slippage and called their "aunt" "he".</p>

<ul>
<li>"Ah, Aunt Julia said he wanted to help me out, too."</li>
</ul>


<h2>Codes Gone Wild</h2>

<p>I've collected some examples of <a href="http://grugq.tumblr.com/post/60890158036/al-qaedas-codes">real al Qaida codes</a> that were used actively used
prior to the 9/11 attacks. Other types of basic open code are "business code",
which is also used by some criminal groups, where the actors are refered to as
business interests or rivals, and criminal activities are described as "projects"
or other innocuous business terms.</p>

<p>A simple code that was used by two KGB operatives was the phrase "I think we
should go fishing now", which indicated that they should discuss business.</p>

<h3>KGB Says What?</h3>

<p>During the early stages of the KGB handling of their FBI penetration Hanssen,
they had a mishap with locating and loading the deaddrop for his payment. To
correct this error, they had to contact Hanssen by phone and use a code that was
not pre-arranged (there was no contingency in place for "what happens if we cant
find the dead drop"). The dead drop location was underneath a footbridge and the
KGB operative had placed his load underneath the wrong corner.</p>

<p>Since they had used a pretext of purchasing a used car for
their initial contact, the KGB continued to use that pretext for their "oops!"
communique. The KGB operative prepared his telephone conversation
thoroughly before hand so that it would sound natural and plausible:</p>

<blockquote><p>KGB: The car is still available for you as we have agreed last time, I prepared
all the papers and left them on the same table. You didn't find them because I
put them in another corner of the table.</p>

<p>Hanssen: I see</p>

<p>KGB: You shouldn't worry, everything is okay. The papers are with me now.</p>

<p>Hanssen: Good</p>

<p>KGB: I believe under these circumstances, its not necessary to make any changes
concerning the place and time. Our company is reliable, and we are ready to
give you a substantial discount which will be enclosed in the papers. Now,
about the date of our meeting. I suggest that our meeting will take place
without delay on Febuary 13, one, three, 1:00 PM. Okay? Feburary 13</p>

<p>Hanssen: .... Okay.</p></blockquote>

<p>The conversations is clearly stilted and strange, but no so strange as to draw
attention to itself. It also doesn't reveal anything of the <strong>meaning</strong> that is
being relayed.</p>

<h3>Signaling Codes</h3>

<p>When creating a signaling code, it is important that the pretext for the signal
be broad and widely applicable. Generally it is better that the code be a
specific subject, rather than a specific phrase. Phrases are easy to mixup,
forget, or otherwise confuse. They are also more rigid and hard to work into
a conversation. A subject, on the other hand, is very easy to raise and discuss
in a plausible fashion without seeming forced or unnatural.</p>

<p>A final short code example. This is a signaling code, adapted from a novel,
however it accurately conveys how simple these codes can be. This is phone call
between two colleagues, where <em>Alice</em> has to signal an emergency has occured:</p>

<blockquote><p>Alice: Hi, sorry to call so late</p>

<p>Bob: No problem</p>

<p>Alice: Is our meeting scheduled for tomorrow at 8:30, or at 9?</p>

<p>Bob: It is 8:30, bright and early.</p>

<p>Alice: Ok, right. Just checking. Thanks, bye</p></blockquote>

<h2>Open Codes Fail Open</h2>

<p>When using a code to refer to a classified subject, even though unclassified terms
are used, the subject is still classified. This is a breach of security. See
the US Army <a href="http://www.ncms-isp.org/documents/COMSEC_Material.pdf">handbook on COMSEC</a>
section dealing with <em>ATTEMPTS TO DISGUISE INFORMATION</em> (Section 8.4).</p>

<blockquote><p>“Talking around” is a
technique in which you try to get the information across to the recipient in a
manner you believe will protect it. However, no matter how much you try to
change words about a classified or sensitive subject, it is still classified or
sensitive.</p>

<p>self-made reference system. This is an
attempt to encipher your conversation by using your own system. This system
rarely works because few people are clever enough to refer to an item of
information without actually revealing names, subjects, or other pertinent
information that would reveal the classified or sensitive meaning</p></blockquote>

<p>These are concerns to keep in mind when developing a code system for discussing
sensitive information.</p>

<h2>Final Thoughts</h2>

<p>Codes: keep them generic, keep them consistent, limit their use to simple signalling.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Yardbird's Effective Usenet Tradecraft]]></title>
    <link href="http://grugq.github.com/blog/2013/12/01/yardbirds-effective-usenet-tradecraft/"/>
    <updated>2013-12-01T07:15:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/12/01/yardbirds-effective-usenet-tradecraft</id>
    <content type="html"><![CDATA[<h1>Survival in an Extremely Adversarial Environment</h1>

<blockquote><p>If your secure communications platform isn't being used by terrorists and pedophiles, you're probably doing it wrong. -- [REDACTED]</p></blockquote>

<p>A few years ago a group of child pornographers was infiltrated by police who were
able to monitor, interact, and aggressively investigate the members. Despite
engaging in a 15 month undercover operation, only one in three of the pedophiles
were successfully apprehended. The majority, including the now infamous leader
<em>Yardbird</em>, escaped capture. The dismal success rate of the law enforcement
officials was due entirely to the strict security rules followed by the group.</p>

<p>This post will examine those rules, the reasons for their success, and the
problems the group faced which necessitated those rules.</p>

<p>(An examination of the group's security from a slightly different perspective
was conducted by <code>Baal</code> and is available <a href="http://dee.su/uploads/baal.html">here</a>)</p>

<h2>Covert Organizations, Seen One, Seen 'em All</h2>

<p>All covert organizations face a similar set of problems as they attempt to execute
on their fundamental mission -- to <strong>continue to exist</strong>. A covert organization
in an adversarial environment faces a number of organizational challenges and
constraints. Fundamentally how it handles trade-offs between operational
security and efficiency mandates how group members perform their operational
activities. Strong OPSEC means low efficiency, while high efficiency necessitates
weak OPSEC. The strength of the oppositional forces dictate the minimum security
requirements of the covert organization.</p>

<p>Examining the operational activities -- those actions the organization must engage
in to self perpetuate -- allows us to evaluate their operational security decisions
within their environmental context.</p>

<h3>Operational Activities:</h3>

<p>The <em>Yardbird</em> child abuse content group (hereafter also called the <em>enterprise</em>)
had a number of core goals that had to be addressed to continue operation: they
needed to distribute their child abuse content to members; communicate between
members; raise funds to acquire new content; recruit new members (presumably for
access to additional child abuse content).</p>

<p>Explicitly stated, this is an enumerated list of the operational activities that
the group <strong>had</strong> to engage in to self perpetuate.</p>

<ol>
<li>Distribution of Child Abuse Content</li>
<li>Communication and Coordinate Action</li>
<li>Fund raising</li>
<li>Recruitment and Vetting</li>
</ol>


<p>Except for the first issue (strategically significant only to this group),
these are pretty typical activities for a clandestine organization. Besides their
defining operational activity, they need a communications channel, fund raising
capability, and membership management processes.</p>

<h2>Opposition Success: The Penetration</h2>

<p>The law enforcement authorities caught a pedophile distribution child abuse
content. He is a member of the <em>Yardbird</em> group and offers up complete access
to the group, along with archival logs, in exchange for leniency.</p>

<p>All of the information about this group comes from the <a href="https://drive.google.com/file/d/0Bzt0K7_O4qyqMi0ycjZFdzhxYTA/edit?usp=sharing">Castleman Affidavit</a>,
the <code>Baal</code> <a href="http://dee.su/uploads/baal.html">analysis</a>, and some <code>Baal</code> <a href="http://alt.privacy.anon-server.narkive.com/VRl3dTFH/the-fourth-of-yardbird-s-chums-grabs-his-ankles">follow ups</a>.</p>

<h2>A Frustrating Infiltration</h2>

<p>The law enforcement authorities were about to completely penetrate the <em>enterprise</em>
for a 15 month period from 2006-08-31 through 2007-12-15. During that time the
group's posted 400,000 images and 1,1000 videos. The <em>enterprise</em> had approximately
45 active members, although <a href="http://alt.privacy.anon-server.narkive.com/VRl3dTFH/the-fourth-of-yardbird-s-chums-grabs-his-ankles">independent observers</a> have claimed this is low with
the real membership anywhere from 48 to 61.</p>

<p>The total number of arrests was 14, or somewhere around 1/3rd. A fully staffed,
highly motivated, well trained adversarial force with complete penetration of
a large complacent group was only about to achieve a one in three success rate.
The majority of those successes were achieved due to group members being insufficiently
cautious and violating the <em>enterprise</em> security rules. Obviously, these security
rules are extremely resilient against adversarial assault.</p>

<p>The members who were caught were those who violated the security SOP of the group:</p>

<ul>
<li>Accessing a newsgroup server without using Tor (e.g. VPN, or directly)</li>
<li>Revealing personal details about themselves</li>
<li>Contacting each other outside the group's secure comms channel</li>
</ul>


<h2>Operational Activity: Distribution</h2>

<p>The <em>enterprise</em> was careful to ensure that the location of the encrypted files
containing child abuse images was a different newsgroup from the communications
newsgroup. One possible reason is to unlink the obvious encrypted group discussion
from the larger encrypted content posts. That is, they compartmented their
commo from their file sharing. As an additional, although superfluous step, the
<em>enterprise</em> would apparently alter the sequence number of the split binary
uploads so that reassembly would be hampered. What this cumbersome step added
beyond the existing PGP encryption is unclear (if your adversary can break PGP
they can probably figure out the order some files).</p>

<h2>Operational Activity: Communications</h2>

<p>The <em>enterprise</em> would use the primary newsgroup, at the start of the investigation
<code>alt.anonymous.messages</code>, to announce the location of a media cache for group
members. The communications newsgroup is always reserved strictly for communications.
The announcements regarding new downloads provided detailed instructions as to
the location of the child abuse content, plus how to download, assemble and decrypt it.</p>

<p>The group used a single shared PGP key for all members. On the one hand, this
would completely negate the security provided by PGP if the key falls into the
wrong hands. It also limits the groups ability to expel a member who transgresses
the rules and needs to be punished. On the other hand, the use of a shared key
makes key management significantly easier which is a serious concern when you
need to rekey every few months. Additionally, using only one key reduces the
ability of the adversary to determine group size by examining the PGP packets.
It also removes the potential for a group member to reuse a key that is linked
to their real identity. See <a href="http://ritter.vg/blog-deanonymizing_amm.html">this excellent</a> presentation for more details on those attacks.</p>

<h2>Operational Activity: Recruitment</h2>

<p>The <em>enterprise</em> expanded by allowing new members to join. There were clear
guidelines, procedures and rules for expansion. First there was a background
check to ensure that the prospective member was an established and active
participant in the wider community of child abuse image traders. Then an existing
member has to invite the prospect to the group. Finally, to demonstrate both
their deep involvement in the activity and to prove they are not an undercover
cop, they must pass a timed written test on the minutiae of various child abuse
victims and media.</p>

<h3>Vetting</h3>

<ul>
<li>Demonstrate active participation in the "trading scene"</li>
<li>Invited by existing member</li>
<li>Must exhibit deep domain specific knowledge via timed written test</li>
</ul>


<h2>Security Rules that Work</h2>

<ul>
<li>Never reveal true identity to another member of the group</li>
<li>Never communicate with another member of the group outside the usenet channel</li>
<li>Group membership remains strictly within the confines of the Internet

<ul>
<li>No member can positively identify another</li>
</ul>
</li>
<li>Members do not reveal personally identifying information</li>
<li>Primary communications newsgroup is migrated regularly

<ul>
<li>If a member violates a security rule, e.g. fails to encrypt a message</li>
<li>Periodically to reduce chance of law enforcement discovery</li>
</ul>
</li>
<li>On each <strong>newsgroup migration</strong>

<ul>
<li>Create new PGP key pair, unlinking from previous messages</li>
<li>Each member creates a new nickname

<ul>
<li>Nickname theme selected by <em>Yardbird</em></li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Root of Success</h2>

<p>The reason the majority of the group was able to avoid capture was in a small way
due to the technology they were using (Tor), but primarily it was adherence to the
security rules of the group. They had very good OPSEC and they followed it
consistently. Fundamentally, they had complete compartmentation within the group
-- they did not reveal information to each other. The
law enforcement authorities were able to get logs of all their communications
traffic, plus logs of their IP addresses they used for posting. Everyone that
used Tor (as per the recommendation of <em>Yardbird</em>) was anonymous at the IP
layer. This protected them from a subpoena revealing their identity. As long as
there was no additional information that they had revealed about themselves in
their messages, they were secure against the opposition.</p>

<p>The use of PGP was essentially a No-OP in this case. It excluded the general
public from accessing the content of the communications traffic (and the child
abuse videos and images). It did not protect the traffic against analysis by the
opposition (who had successfully infiltrated the group). The encryption was not
a factor in their successful evasion. Rather, it was the content of the messages,
controlled and dictated by the security rules, which protected their secrets.</p>

<h2>Lessons Learned</h2>

<p>Guarding secrets involves not sharing them. Encryption can only ever protect the
content of a communique. Real security must start with the content itself, and
then use encryption as an additional layer.</p>

<h3>Note from the Editor</h3>

<p>(Feel free to skip this part if you don't think studying how child pornographers
avoid capture is relevant)</p>

<p>When analyzing the activities of groups operating in an adversarial environment to learn what works, what doesn't, and why, (unfortunately) the pool of covert organisations is somewhat limited: intelligence agencies; terrorist groups; hacker crews; narcos; insurgents; child pornographers... Few other groups face such a hostile operating environment that their security measures are really "tested".</p>

<p>The group examined in this post had an incredibly effective set of security practices. They imposed strict compartmentation, regularly migrated identities and locations, required consistent Tor and PGP use, etc. They had legitimate punishments for people who transgressed the rules (expulsion) and they survived a massive investigation effort. Clearly, they were doing something right (actually a number of things).
Just as clearly, they are reprehensible people who engage in activity that is immoral and unethical, by any measure. (Paying for child pornography to be produced is flat out wrong, regardless on where you stand on the spectrum of <a href="http://falkvinge.net/2012/05/23/cynicism-redefined-why-the-copyright-lobby-loves-child-porn/">opinions regarding child porn laws</a>).</p>

<p>The thing is, there are basically no nice people who provide case studies of OPSEC practices. Most are engaged in violence, serious drug trafficking (at the "kill people for interfering" level), theft and manipulation of human beings, etc. Thats the nature of the beast.</p>

<p>People with well funded, trained and motivated adversaries have the strongest incentives to practice the highest level of security. They're the ones to learn from.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Win at Kung Fu and Hacking]]></title>
    <link href="http://grugq.github.com/blog/2013/11/22/challenges-for-hackers/"/>
    <updated>2013-11-22T20:02:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/11/22/challenges-for-hackers</id>
    <content type="html"><![CDATA[<h2>Everybody Was Hack Foo Fighting</h2>

<p>I'm going to discuss a serious problem with the organisational structure and
social dynamics of the hacker community, and why this puts hackers at risk.
Hackers operate essentially the same way as the henchmen in a kung fu movie:
they attack the adversary one by one by one... always losing. This is a terrible
way of developing a robust core of knowledge about which OPSEC techniques work,
which techniques fail, and why.</p>

<h2>Organisational Learning for Dummies</h2>

<p>There are two types of knowledge: individual, and organisational. Hackers are
very individualistic, and the knowledge they acquire tends to be very
practical; experience based. There are few hacker organisations that seek to
collect, retain, test and spread knowledge. The organistations that do crop up
are either some zines, which are knowledge artefacts that transmit techne, or
hacker groups, which share tool chains and experience. However, these hacker
groups have very short lifespans (measured in months and single digit years,
not decades). They are compartmented in that there is some effort made to
retain the group's proprietary information, but internally they usually
have a very poor security posture. They are social groups in many ways, so
they are heavily compromised. As we say in infosec "crunchy on the outside,
chewy in the middle".</p>

<p>Their opposition, the intelligence agencies and law enforcement departments,
have decades of organisational history and knowledge. The individual members
can display wide ranges of skill and competence, but the resources and core
knowledge of the organisation dwarf what any individual hacker has available.
Many of the skills that a hacker needs to learn, his clandestine tradecraft
and OPSEC, are the sort of skills that organisations are excellent at
developing and disseminating. These are not very good skillsets for an
individual to learn through trial and error, because those errors have
significant negative consequences. An organisation can afford to lose people
as it learns how to deal with the adversary; an individual cannot afford to
make a similar sacrifice -- afterall, who would benefit from your negative
example?</p>

<h2>Challenges? More Like Opportunities!</h2>

<p>Hackers are facing some very serious challenges now:</p>

<ul>
<li>they lack organistations for collecting intelligence and knowledge about their adversary;</li>
<li>they face off against the adversary one at a time,</li>
<li>they learn very poorly from prior mistakes</li>
<li>they don't even know what skills they need,</li>
<li>and perhaps most dangerously, they aren't even aware they're in the game</li>
</ul>


<p>It is amusing how many people think that interrogations involve violence and
torture. Successful elicitation far more frequently involves whiskey,
flattery, playing dumb, and being doubtful ("<em>really? I didn't know it was
possible to do that. You must be pretty damn smart to have figured it
out...</em>").</p>

<h2>Winning at Secrets</h2>

<p>There needs to be more information available on the techniques used during
investigations, as well as before they begin. There needs to be documentation
on how to evade those techniques, and why those evasions are successful. That
knowledge needs to be captured and dissemminated out to those who can use it.</p>
]]></content>
  </entry>
  
</feed>
