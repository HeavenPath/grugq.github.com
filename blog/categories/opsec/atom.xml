<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: OPSEC | Hacker OPSEC]]></title>
  <link href="http://grugq.github.com/blog/categories/opsec/atom.xml" rel="self"/>
  <link href="http://grugq.github.com/"/>
  <updated>2013-10-09T19:46:01+07:00</updated>
  <id>http://grugq.github.com/</id>
  <author>
    <name><![CDATA[the grugq]]></name>
    <email><![CDATA[the.grugq@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[It was DPR]]></title>
    <link href="http://grugq.github.com/blog/2013/10/09/it-was-dpr/"/>
    <updated>2013-10-09T19:44:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/10/09/it-was-dpr</id>
    <content type="html"><![CDATA[<h2>Give it to me straight, dr the grugq</h2>

<p>Generally, it appears that Ross Ulbricht was applying his economic and
techno-libertarian philosophy to real life. As his project grew, his security
posture improved -- too late. The most serious mistakes that Ross Ulbricht made
were made during the period Jan 2011 - Oct 2011. A full timeline of the events
in the Complaint is available on <a href="http://grugq.tumblr.com/post/62914009002/silk-road-investigation-timeline">my tumblr</a>.</p>

<p><strong>NOTE:</strong> This is an abridged version of a longer post pulling out the lessons learned
from the <a href="http://grugq.tumblr.com/post/62909883417/ulricht-indictment-aka-dread-pirate-roberts-aka-silk">Silk Road Complaint</a> of 27th September 2013. This post will only list the OPSEC errors,
rather than explore them in detail.</p>

<h2>The OPSEC Failures</h2>

<p>The fundamental error is poor compartmentation. Ross Ulbricht, the real person
and the online persona (Google+, LinkedIn, etc), and the Dread Pirate Roberts
persona share ideological views and geographic locations. There is contamination
between the two personas. Most of these seem to be due to the organic evolution
of the Silk Road venture, where early naive Ulbricht makes mistakes that later
smarter DPR wouldn't. Unfortunately, the later DPR is more ideologically
extreme and consequently less savvy about mainstream society.</p>

<ol>
<li>Poor Compartmentation</li>
<li>Profiling</li>
<li>Geographic Location</li>
<li>Isolation</li>
</ol>


<h3>Poor Compartmentation</h3>

<ul>
<li>Contamination: seriously fatal links created between personas

<ul>
<li><strong>Silk Road</strong> + <strong>altoid</strong>: Shroomery, BitcoinTalk forums</li>
<li><strong>altoid</strong> + <strong>rossulbricht@gmail.com</strong>: BitcoinTalk</li>
<li><strong>Ross Ulbricht</strong> + <strong>frosty@frosty[.com]</strong>: StackOverflow</li>
<li><strong>frosty@frosty</strong> + <strong>Silk Road</strong>: Silk Road server admin SSH key</li>
</ul>
</li>
</ul>


<p>The compartmentation failures are somewhat pervasive, in particular the ideological
"Austrian School of Economics" and the mises.org site. However two particular
contamination errors stand out:</p>

<ol>
<li><strong>Silk Road</strong> --> <strong>altoid</strong> --> <strong>rossulbricht@gmail.com</strong> link in 2011</li>
<li><strong>Ross Ulbricht</strong> --> <strong>frosty@frosty.com</strong> --> <strong>Silk Road</strong> server link in 2013</li>
</ol>


<p>The first of these failures happened because the <strong>altoid</strong> persona used to
promoted <strong>Silk Road</strong> was poorly fleshed out (no email address). Ross did not
put the plumbing in place and backstop his <strong>altoid</strong> cover. Then he joined and
started the BitcoinTalk community and started participating. This left him with
his guard down and he revealed a great deal of profiling information about his
project and beliefs. Many of his posts are about Silk Road infrastructure or
his mises.org influenced economic theories. After participating for 10 months
he finally made the <strong>fatal OPSEC error</strong> of posting his personal email address.</p>

<p>The second error was poor compartmentation of his online Ross Ulbricht persona,
the tech savvy San Francisco based startup guy, and "frosty" the system admin
of the server hosting the Silk Road site. His poor compartmentation, likely
using the same computer for both personal and business use, and his
limited backstopping of the DPR/altoid/frosty persona meant that any error was
fatal.</p>

<p>These two errors combine to link Silk Road with Ross Ulbricht, and Ross Ulbricht
with Silk Road.</p>

<h3>"I'll take Profiles for $300, Alex" : "Too much in common" : "What do Ulbricht and DPR share?"</h3>

<ul>
<li>Profiling: Ross Ulbricht talks and acts like Dread Pirate Roberts

<ul>
<li>LinkedIn profile</li>
<li>Timezone leakage: private messages, <a href="http://media.encrypted.cc/files/dpr_posts_pdt.png">forum posting times</a></li>
<li>BitcoinTalk <strong>altoid</strong> <a href="http://grugq.tumblr.com/post/62919678278/osint-case-study-ross-ulbricht-aka-dread-pirate">posts about</a>: economics (mises.org), security, programming</li>
<li>Silk Road Forum <strong>Dread Pirate Roberts</strong> -> Mises + "Austrian School of Economics"</li>
<li>Mises.org <strong>Ross Ulbricht</strong> account</li>
</ul>
</li>
</ul>


<p>Ross Ulbricht, the person, was an active participant in the mises.org website
and the BitcoinTalk forums. In both cases he was deeply committed to the
"Austrian School of Economics", something the Dread Pirate Roberts was also a
huge fan of. The <strong>altoid</strong> cover alias, linked directly to Ross Ulbricht,
frequently talked about bitcoin security and PHP programming. He is, based on
his posts, clearly invovled in running some sort of PHP based bitcoin using
venture that requires high security. Sort of like the <strong>Silk Road</strong> site.</p>

<ul>
<li>Geographic Location

<ul>
<li>Silk Road web server administered over VPN from a server</li>
<li>VPN server IP stored in the Silk Road PHP source code</li>
<li>VPN server accessed from a location <code>15240 cm</code> (<code>500 ft</code>) from a location that accessed the Ross Ulbricht GMail account.</li>
</ul>
</li>
</ul>


<p>The location of the Dread Pirate Roberts was something of an open secret. It is
clear that he was based in the west coast of the US. Ulbricht was located
in San Francisco at the same time as DPR, as proved by his large online
footprint: Google+, YouTube, GMail.</p>

<h2>Isolation is bad, mmmkay</h2>

<ul>
<li>Isolation without relief

<ul>
<li>Rented room under assumed name</li>
<li>No "mainstream" social circle to realign with social mores</li>
<li>No peers to talk to, only Silk Road forum members and admins</li>
</ul>
</li>
</ul>


<p>After the <strong>altoid</strong> persona is retired from BitcoinTalk, Ulbricht migrates
his social interaction to a more extreme community: the Silk Road forums. This
appears to have been his "scene", where he interacted with people and
cultivated friends (including an impressive array of undercover law
enforcement officials).</p>

<p>The underground life forced on Ulbricht as the Dread Pirate Roberts led to
the major problem of isolation. Human beings are social animals. We require
social interaction to maintain a healthy mental state. The strict
security of DPR required isolation, leaving Ross Ulbricht living his social
life on forums with niche ideological views, initially BitcointTalk (in 2011)
and then the Silk Road forums. Isolation from mainstream society is known to
lead to ideological extremism as members of the niche community self-reinforce
their ideological tendencies. Consequently, they are less able to understand
mainstream society's ideas, beliefs and morals. This is dangerous. This
isolation leads him to rationalize hiring online hitmen to preserve the
Silk Road community is morally acceptable.</p>

<h2>What have we learned?</h2>

<p>So, the Dread Pirate Roberts Complaint basically tells us nothing that we didn't
already <a href="http://www.slideshare.net/grugq/opsec-for-hackers">know about OPSEC</a>.
There are some lessons learned which can be used to harden OPSEC practices going
forward. The main things are still, strong compartmentation, use Tor
all the time, avoid leaking profiling information, and finally it is
prudent to regularly migrate to new cover personas.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Drug Delivery Service OPSEC]]></title>
    <link href="http://grugq.github.com/blog/2013/10/07/drug-delivery-service-opsec/"/>
    <updated>2013-10-07T06:41:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/10/07/drug-delivery-service-opsec</id>
    <content type="html"><![CDATA[<p>Some interesting lessons on how a modern New York City drug delivery service
uses basic tradecraft to create a reasonable security posture.</p>

<h2>The Source</h2>

<p>This <a href="http://www.vice.com/read/confessions-of-a-drug-dealers-delivery-service-guy">Vice article</a>
provides the source of the information for this blog post. Using some
basic background knowledge on how covert groups operate, it is simple to parse
and analyze the drug delivery service tradecraft.</p>

<h2>Recruitment</h2>

<blockquote><p>a friend of mine solicited hardcore drugs for a Manhattan drug kingpin, who was looking for a new pot delivery guy. My friend encouraged me to try out for the job.</p></blockquote>

<p>As with many covert groups, the recruitment process relied on personal connections.
This <strong>social network</strong> grounded approach to expanding a covert organisation
is generally good for initial security. The recruits are unlikely to be agents
sent to infiltrate the organistation as the long standing social ties between
members and recruits both establishes trust and serves as <strong>vetting</strong>.</p>

<p>Developing a covert organisation based on <strong>social network</strong> ties provides a
means of rapid expansion and easy security clearance. The downside is that once
a single member of the organisation is compromised, the adversarial security forces
can easily roll up the whole network. The poor compartmentation of a <strong>social network</strong>
based covert organisation is its Achilles heel. The security of the organisation
is critically dependent on the security of each individual member.</p>

<p><strong>ProTip:</strong> Expand your covert network with individuals who are passionate about
your ideological beliefs. Ensure strong compartmentation, starting with recruitment.</p>

<h2>Leverage</h2>

<blockquote><p>He asked me to provide documentation of my current address and phone number as an insurance policy. If I ran out on him, he warned me he’d hold my friends responsible for the deficit funds and/or drugs.</p></blockquote>

<p>The principal of the organisation "Nathan" requires that the recruit provide
a verifiable address and means of contact, along with dire warnings of consequences
in the case of infractions. This is very basic control principles, typical of
covert organisations.</p>

<p>The major security problem with this approach, of course, is that the records
maintained by the network's principal are a high value target for the adversary.
Compromise of the principal's records will lead to total collapse of the network,
and interdiction for every member involved. There is no chance of evasion.</p>

<p><strong>ProTip:</strong> No logs, no crime. Do not keep records of the members of your covert
organisation. These records are extremely sensitive.</p>

<h2>Operational Actions</h2>

<blockquote><p> the transaction and exit should be as swift as possible. “You aren't here to hang out,” she said. “It's not a social call, and they aren't your friends. You want to walk in and be friendly and make conversation but also get to the business at hand and get out of there quickly.”</p></blockquote>

<p>The illicit operation, the drug sale, is intended to be rapid and minimize
the period of vulnerability for both parties. Interestingly, this is possibly a
poor choice if the threat is surveillance. There are few reasons a random individual
would enter a domicile for a short duration. Also of note, the covert organisation
provides no reasonable cover story for why the agent (the drug courier) is entering
the residence of the client. A simple "what were you doing?" type question would
likely completely blow the whole operation.</p>

<p><strong>ProTip:</strong> Minimising the period of vulnerability improves the chances of operational
success. Always make sure your agents are capable of delivering plausible cover
stories. <strong>Cover for action</strong></p>

<h2>Cover for Status</h2>

<blockquote><p>Nathan forced me to wear a button-up shirt and slacks, shave my face, and keep my hair conservatively short. He believed this uniform would attract little attention as I walked around with thousands of dollars worth of pot in a laptop case slung over my shoulder.</p></blockquote>

<p>The covert organisation has, surprisingly enough, chosen to enforce a uniform
that makes their agents blend in with the mainstream. This is completely inline
with the typical operational disguises employed by covert organistations operating
in controlled territory the world over. (See: Moscow Rules <code>go with the flow</code>;
Murphy's Laws of War: <code>don't stand out, it draws fire</code>)</p>

<p><strong>ProTip:</strong> They got this one exactly right.</p>

<h2>All phones are bugged</h2>

<blockquote><p>Although I used my flip-phone constantly at work, I was never given clients' addresses over the phone. Clients calls would go to a dispatcher—a third party who took the call, traced the number through a database of numbers, and then returned the call from a different phone to confirm their request for drugs. After their request was confirmed, I received a call from another phone. The dispatcher only told me, “You got Nick,” or “You got Lucy.” I was banned from responding with anything besides a murmured “OK.”</p></blockquote>

<p>Each operational use of the phone provides the adversary with minimal value.
There is a unique identifier for the client (e.g. "Lucy"), and the agent
acknowledges receipt of the directive ("OK"). The dispatchers interaction
with the client is itself run over multiple phone lines and kept to short,
simple, normal statements.</p>

<p><strong>ProTip:</strong> This is very much inline with all covert organisations'
guidelines for using phones. Never use keywords, keep the content as vague as possible,
minimize the period of vulnerability -- get off the phone!</p>

<h2>OPSEC FAIL: attracting attention</h2>

<blockquote><p>Each day I was given a stipend of $40 for cabs. No one knew if I didn’t spend the $40. Instead of taking cabs, I ran around in a frantic state that negated every other measure I took to not draw unwanted attention</p></blockquote>

<p>This is an instance of <strong>preference divergence</strong>, a common problem for covert
organisations. The financial resources provided to the agent of the principal
are siphoned off and directed towards non-operational uses (the drug courier
skims and pockets his cab stipend.) There doesn't appear to be any consequence
to this operational security failure, however it jeopardizes the entire organisation.
If "Nathan" were a more disciplined principal he would monitor his agents more
closely and ensure they are conforming to the organisational security requirements.
Strangely, drug dealers are not strict disciplinarians.</p>

<p><strong>ProTip:</strong> if the securit of the entire organisation is dependent on the security
of each individual agent -- enforce the operational security requirements strictly!</p>

<h2>Aliases</h2>

<blockquote><p> I shook his hand and said, “I'm Jack.” He gave me a knowing grin. “So that's the name you're using?” he asked.</p></blockquote>

<p>The agent is using an alias to provide pseudonymity from malicious clients. This
provides some minimal level of security. It is definitely better than not having
any cover at all. However, as noted above, it should be combined with a robust
cover story for why the agent is visiting a residential home for a brief period.</p>

<h2>Discharging the agent</h2>

<p>After a promotion, the drug courier decides to find a new line of work. If the
organisation was stricter in their OPSEC practices, the departure of an agent
wouldn't place anyone else in jeopardy. As it stands, it seems clear that the
agent who is now drawing attention to himself by writing about his experience
in a national magazine(!) still retains sufficiently sensitive information to
unravel the network.</p>

<p><strong>ProTip:</strong> compartment early, compartment often. It is safer than any alternative.</p>

<h2>TL;DR</h2>

<p>Compartment your covert organisation from recruitment through to operational
action so that when your agents leave or are compromised they are unable
to compromise the organisation. Ensure that your operational activities have
good <strong>cover for status</strong> (e.g. a disguise) and <strong>cover for action</strong> (e.g. a strong cover story).
Strong compartmentation, strong cover, and be aware of the risks of using social networks
for building a covert organisation.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Thru a PORTAL Darkly]]></title>
    <link href="http://grugq.github.com/blog/2013/10/05/thru-a-portal-darkly/"/>
    <updated>2013-10-05T15:08:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/10/05/thru-a-portal-darkly</id>
    <content type="html"><![CDATA[<h2>The Design and Implementation of P.O.R.T.A.L</h2>

<p>The <strong>P</strong>ersonal <strong>O</strong>nion <strong>R</strong>outer <strong>T</strong>o <strong>A</strong>ssure <strong>L</strong>iberty is designed
to protect the user by isolating their computer behind a router that forces all
traffic over the Tor network.</p>

<h2>PORTAL Gooooooooooooooaaaaaaaaaaals!!!!!!</h2>

<p>The goal of the PORTAL project is to create a compartmented network segment
that can <strong>only</strong> send data to the Tor network. To accomplish this the PORTAL
device itself is physically isolated and locked down to prevent malicious
tampering originating from the protected network. So if the user's computer is
compromised by malware, the malware is unable to modify the Tor software or
configuration, nor can it directly access the Internet (completely
preventing IP address leakage). Additionally, the PORTAL is configured to fail
close -- if the connection to Tor drops, the user loses their Internet access.
Finally, the PORTAL is "idiot proof", simply turn it on and it works.</p>

<h2>The Implementation, the Pain, the Horror</h2>

<p>The initial requirement was to develop PORTAL for a small personal sized router,
such as the TP-Link 703N, 3040, or M1U. All of these devices are small, portable
and support the OpenWRT open source router firmware. Unfortunately, it turns out
that "small" and "portable" is synonymous with "weak" and "underpowered".</p>

<p>Unfortunately, Tor is quite resource intensive for an embedded device. Tor uses 16MB of RAM
and for complete functionality (requiring the GeoIP database) it occupies slightly
over 1.2MB of <code>squashfs</code> space. The stock TP-LINK routers have only 4MB of flash
and 16MB of RAM (later models have increased RAM). This caused a lot of problems
when building early versions. A bare bones OpenWRT system stripped down to just
support an Internet uplink USB device occupies 3.2MB of <code>squashfs</code> space. Using
the power of math we see: <code>3.2 + 1.2 &gt; 4.0</code>. Fuck.</p>

<h3>Enter The Dragon, or Chinese Hackers to the Rescue</h3>

<p>Fortunately, the TP-LINK routers are not just small, they are also extremely hackable. They are very popular
with hackers who have modified the hardware and expanded the capabilities of the
stock device. I got in contact with a Chinese hacker who has upgraded the
TP-LINK 703N to 16MB of flash and 64MB of RAM. Sweet. Using these modified routers
development of the PORTAL became much much easier.</p>

<h2>PORTAL System Architecture</h2>

<p>The PORTAL requires a minimum of two network interfaces: one for the Internet
uplink, and one for the isolated network segment. In order to protect the PORTAL from
tampering from malware (or malicious users), it also requires a third administration
interface. This can be either a serial console, or physical connection. The reason
not to use WiFi for the administration network is that that would expose the
administration interface to anyone within WiFi range, including potentially the
user's compromised laptop's WiFi card.</p>

<h3>Three Interfaces to Rule Them All</h3>

<p>The requirement to protect the PORTAL from a malicious user caused some problems
since the device hardware has very limited interfaces. The TP-LINK 703N has only:</p>

<pre><code>* 1 x USB 2.0
* 1 x 100MB ethernet
* 1 x onboard wifi
</code></pre>

<p>All available interfaces are required to get us to the three networks we need:</p>

<pre><code>* Tor: isolated proxy interface
    * Tor SOCKS proxy
    * Tor Transparent TCP proxy
    * Tor Transparent DNS proxy
    * DHCP (optional)
* Admin: configuration management interface
    * ssh
    * https (optional)
    * DHCP (optional)
* Internet: uplink connection interface
    * No services
</code></pre>

<h2>Operational PORTAL</h2>

<p>After the user has configured the <code>Internet</code>, and whatever other adjustments they
wish to make, they shouldn't need to connect to the <code>Admin</code> interface again. This
leaves us with a very hard target for any attacker who wishes to unmask us
(modulo any issues with Tor itself).</p>

<p>The PORTAL has been hardened to make it significantly more difficult for the user
to make a mistake, or for an attacker to subvert the Tor protections. From the
<code>Tor</code> network the only exposed ports are Tor's DNS proxy, TCP proxy, and SOCKS.
Optionally, you can use DHCP on this network.</p>

<p>If, somehow, the firewall doesn't work properly, you're still safe because the
PORTAL doesn't actually route packets. The <em>only</em> way you can reach the Internet
(regardless of which interface you're connected to) is via Tor. This stops stupid
mistakes, such as connecting to the <code>Admin</code> interface and forgetting to swap to
the <code>Tor</code> network. Don't worry, you can't do that, it won't work, you're welcome.</p>

<p>Final hardening is left up to the user who will have to assign the <code>Admin</code> and
<code>Tor</code> networks to physical interfaces. There are security trade offs either way.</p>

<ul>
<li><p>Medium Security:</p>

<ul>
<li><code>Tor</code> = WiFi</li>
<li><code>Admin</code> = Ethernet</li>
<li>pros: ease of use</li>
<li>cons: pre-Tor plaintext will be broadcast over the AEther (see: Hammond)</li>
</ul>
</li>
<li><p>Maximum Security:</p>

<ul>
<li><code>Tor</code> = Ethernet</li>
<li><code>Admin</code> = WiFi</li>
<li>pros: ultra secure</li>
<li>cons: if an attacker cracks your WPA2 PSK, they'll have access to your
    management sshd. Of course, they'll be so physically close to you
    at that point, leaking your IP is the least of your worries.</li>
<li><strong>NOTE:</strong> remote the WiFi card from your computer to block access via
      malware compromise</li>
</ul>
</li>
</ul>


<h2>Just Do It</h2>

<p>The PORTAL project has been migrated to the RaspberryPi, which has more power
to support Tor. It requires more configuration, which is something I'll work on,
however the ease of acquisition of the RPi makes this the current platform of
choice. So go install <a href="http://github.com/grugq/PORTALofPi">PORTAL of Pi</a> and
compartment all of your sensitive operational activities inside an isolated Tor network.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[you can't get there from here]]></title>
    <link href="http://grugq.github.com/blog/2013/06/14/you-cant-get-there-from-here/"/>
    <updated>2013-06-14T10:06:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/06/14/you-cant-get-there-from-here</id>
    <content type="html"><![CDATA[<p>There have been some responses to my <a href="http://grugq.github.io/blog/2013/06/10/good-luck-with-that/">post</a> about the limitations of public
countersurveillance tools. Most of them have focused on my statements about
the limitations of the Tor network. I started to write a comment addressing one of the more coherent
<a href="http://www.reddit.com/r/onions/comments/1g437b/the_surveillance_capability_of_the/cagw3vb">replies</a>
but then decided to simply post it here instead.</p>

<h2>Rebuttal</h2>

<p>The responses all wandered slightly off topic from what my post was about. The point was that simply installing and running off the shelf counter-surveillance software is not sufficient against a nation state level adversary. Saying "Install Tor" or "Install I2P" is not the correct way to develop a counterintelligence program. It is not even the correct place to start. While those tools may be components of a CI program, but they are not sufficient in and of themselves.</p>

<p>To expand on what I was getting at in the post, the core issue is that when Tor and I2P and other countersurveillance solutions are developed, they are developed with certain assumptions about the capabilities of the adversary. For example, Tor does not work against an adversary who has total information awareness about the traffic on the Internet. The assumption for Tor is "adversary can monitor a subset of all IP traffic", where subset usually equals "a single country". Because we, the public, do not know the real capabilities of the adversary, those assumptions might be (and in some cases, likely are) completely incorrect. In this example, it is widely suspected that the US has the capability to monitor a significant portion of global IP traffic, not just limited to a single country. At a minimum we can assume that they will be able to get traffic logs for 5 eyes members, and most likely for all of NATO.</p>

<p>My article makes the claim that these off the shelf countersurveillance networks are insufficiently secure against nation state level adversaries. I also claim that we don't know the capabilities of those adversaries, and therefore cannot know what technology would evade their surveillance capabilities. I stand by both claims.</p>

<p>My point regarding the cost of doubling the count of Tor exit nodes is simply that the financial cost of compromising the Tor network is not even a rounding error in a nation state budget. It is the equivalent of a portion  of the change found in the couch. Further more, Tor is not new. It isn't as if nation state level adversaries just woke up last week, "holy shit, this Tor thing! we better get on that!". It is conceivable that a nation state has been setting up cover organisations, using agents, and compromising existing hosts for years with the sole goal of subverting the security of the Tor system. We have no way of knowing this because we have limited/no knowledge of their capabilities. Which was exactly my point.</p>

<h2>Evil Exit Nodes Unmasked me, and all I got was this lousy jail term</h2>

<p>To address the specific objections about "all smart Tor users know to encrypt traffic to combat malicious exit nodes": yes malicious snooping nodes can be evaded provided you are using encryption to another termination point. This is why I've recommended using a VPN over Tor to mitigate against the monitoring that <em>is</em> done by evil exit nodes. However, an additional problem with a malicious exit node is simple traffic analysis, where the content of the data is irrelevant, but unmasking the end user is still possible. There are cases where unmasking an end user is sufficient, if they are going to "www.how-do-I-wage-jihad-in-the-usa.com.ir", for example. If we take the case of a nation state level adversary who can monitor all IP traffic within their country, and we combine that with the same adversary operating (or monitoring) a significant percentage of exit nodes, then that adversary can trivially unmask Tor users. The cost of this operation would be well within the budget of any respectable intelligence agency.</p>

<h2>Backlash caused severe pain in my lower nonspecific</h2>

<p>Regarding risk of backlash if it is known that a nation state has compromised all (or many) ISPs: Firstly, we can all agree that the compromise of an ISP is well within the scope of an intelligence agency. If you have been around the underground long enough, you know how many different people and groups have compromised Tier 1 ISPs. But regarding the "backlash", a nation state adversary will classify everything that could leak their tools, techniques and procedures. The means by which they collect information is usually as classified, or even more classified, than the information they collect. It is not likely that they would ever willingly allow this information to become known. Frequently intelligence agencies will classify information simply because revealing that they know it would reveal their collection capability, and thus compromise their ability to exploit that capability in the future.</p>

<p>Which is what brings me back to the point I was getting at in the post. If you are engaged in activities which will put you up against a nation state level adversary, you have no knowledge of what their capabilities are. Fortunately for just about everyone (reading this), you do not have a nation state level adversary. A law enforcement agency, such as the FBI, will have access to some nation state level capabilities in certain circumstances. For example, if it was known that a trained al Quaida cell was operating in the continental US and using Tor for their communications platform, the NSA would very likely use whatever Tor unmasking capability they have to assist the FBI. They would do this in a blackbox fashion: get a request -> send a response. They would not reveal <em>how</em> they performed the unmasking because the FBI would not have people who are cleared for that information. (This is compartmentation in action.)</p>

<p>As a thought experiment, imagine that Osama bin Laden was still alive and that he used the Tor network to do a Reddit AMA once a month. How long do you imagine it would take for the US to find and neutralize him? I posted <a href="https://twitter.com/thegrugq/status/344492461432926208">this question</a> on Twitter and, while responses varied, ex-NSA Global Network Exploitation Analyst Charlie Miller guessed <a href="https://twitter.com/0xcharlie/status/344498844161155072">one to two months</a>. I would be very surprised if it took more than three. This is because OBL <em>had</em> a <strong>nation state level adversary</strong>. You (probably) do not.</p>

<h2>Good news everyone, nobody gives a fuck</h2>

<p>There is good news, of course. Nation state level adversaries are concerned about nation state actors (and some non-nation state actors). They really don't have the resources to spend monitoring law enforcement issues. Unless you are a policy maker, a ranking military official, an intelligence officer/agent, a member of a known terrorist organisation, or have somehow otherwise ended up on a targeting list, the Intelligence Community (IC) really doesn't give a fuck about you. The product they produce for their clients - security cleared government officials - is documentation and analysis that helps these officials make informed policy decisions (or at least, that is the intention).</p>

<h2>You Should OPSEC anyway</h2>

<p>Now, as I advocate elsewhere, it is best to start your counterintelligence program early, because after you are targeted it is (usually) too late.</p>

<p>My central recommendation on how to operate safely, whether you are a hacker, a spy, a whistleblower, or whatever, is to implement compartmentation first. Classify the data which is sensitive (e.g. your real identity and anything linked to your real identity) and segregate it from everything related to your illicit activity. Preferably, by physically separating onto different machines. When conducting the illicit activity, use your illicit activity equipment, and do it over an internet link that cannot be linked to you. By all means, use Tor, or I2P, or a VPN, or whatever. But that technology must not be your primary and only line of defence.</p>

<p>This is how you do good CI. Develop a SOP that will protect your sensitive data even when things fail.
That said, most of what will sink people is poor OPSEC, not poor SIGSEC. The more people that know about your illicit activity the higher the chance that Murphy will raise his head and it'll all end in tears.</p>

<h2>Counterintelligence Cliff Notes</h2>

<p>So, to reiterate, choosing a technology first and then relying on it for security is completely ass backwards. To do things properly, operate in this order. Figure out what you are trying to protect (and from whom), separate it from everything else, and then select tools, techniques and procedures that will enable you to protect it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ignorance is strength]]></title>
    <link href="http://grugq.github.com/blog/2013/06/13/ignorance-is-strength/"/>
    <updated>2013-06-13T01:02:00+07:00</updated>
    <id>http://grugq.github.com/blog/2013/06/13/ignorance-is-strength</id>
    <content type="html"><![CDATA[<p><blockquote><p>Seven, this rule is so underrated<br/>Keep your family and business completely separated</p><footer><strong>Biggie Smalls</strong> <cite>Counterintelligence Theory and Practice for Crack Dealers</cite></footer></blockquote></p>

<h2>Guerrillas, Terrorists, Narcos, Spooks, and You</h2>

<p>Guerrillas, terrorists, narcos and spooks the world over have learned the hard
way how to keep their illicit activity safe from their opponents. The same principles
of counterintelligence (CI) that help protect them from death can
be applied to protect you from your adversary. If you engage in behavior
that carries the risk of negative consequences from an adversary, you will need
to develop and implement a robust CI program. This post will explain the foundations of
strong OPSEC, a critical part of just such a program.</p>

<h2>Establish Cells, or Live in One</h2>

<p>The cornerstone of any solid counterintelligence program is <strong>compartmentation</strong>.
Compartmentation is the separation of information, including people and activities,
into discreet cells. These cells must have no interaction, access, or knowledge
of each other. Enforcing ignorance between different cells prevents any one
compartment from containing too much sensitive information. If any single cell
is compromised, such as by an informant, the limitats of the damage will be at
the boundaries of the cell.</p>

<p>Now, compartmenting an entire organisation is a difficult feat, and can
seriously impede the ability of the organisation to learn and adapt to changing circumstance.
However, these are are not concerns that we need to address for an individual
who is compartmenting their personal life from their illicit activity.</p>

<p>Spooks, such as CIA case officiers, or KGB illegals, compartment their illicit
activity (spying) from their "regular" lives. The first part of this is, of course,
keeping their mouths shut about their illicit activities! There are many other
important parts of tradecraft which are beyond the scope of this post. But remember,
when you are compartmenting your life, the <strong>first rule</strong> is to never discuss your
illicit activities with anyone outside of that <strong>compartment</strong>.</p>

<h2>Compartmentation For Dummies</h2>

<p>This will cover a basic set of guidelines for compartmenting a particular online
activity. In our hypothetical scenario there are two people, Alice and Bob (natch),
who want to exchange information with each other. They are deathly afraid that
the adversary will learn (in ascending order of risk to Alice):</p>

<ul>
<li>Two people have been in contact (low risk)</li>
<li>Bob has been in contact with someone (medium risk)</li>
<li>Alice has been in contact with someone (high risk)</li>
<li>Alice has been in contact with Bob (extreme risk)</li>
</ul>


<p>While this guideline is a starting point for someone who seeks to conduct illicit
activity under hostile internet surveillance it is not concrete set of rules.
When developing a CI program you must evaluate the threats and risks to yourself
and create a custom set of tools and procedures that address your needs. The
specific SOP that you develop for will differ from the outline below, but if it
is to be resilient against the adversary it must be based on some form of compartmentation.</p>

<h2>Step 1: Cleanliness is Next to Not-Being-in-Jailiness.</h2>

<p>Alice must purchase new dedicated equipment used exclusively for communicating
with Bob. This means, buy a new laptop. Don't bother with a new virtual machine,
that isn't sufficiently compartmented. Any existing equipment that Alice owns
might already be compromised and is therefore not safe against potential monitoring.</p>

<p>The software installed should be the bare minimum of generic utilities required
to do the communications. Here is an example setup:</p>

<ul>
<li>Laptop (cover the webcam with tape, disable the mic if possible)</li>
<li>Virtualization Software (VBox, VMware, Parallels, etc)</li>
<li>Ubuntu installed in the VM (disable all the logging + reporting)</li>
<li>Recommended Software:

<ul>
<li>Tor Browser bundle</li>
<li>PGP (generate and store new keys on a USB drive)</li>
<li>OTR enabled chat client</li>
</ul>
</li>
<li>Snapshot the VM</li>
</ul>


<p>This is the base platform that Alice will use when contacting Bob. Obviously,
Bob should go through the same process (if he faces similar risks, or is concerned
about Alice's wellbeing).</p>

<p>The usernames and hostnames used should be generic, not associated with Alice's
real name, location, place of work, etc. If the VM is compromised, there will be
no identifying information, or keys that can be used to decrypt previous comms.
If the VM is escaped and the adversary has access to the host, again, there will
be no identifying information. The host machine has only the virtualization software
on it. Use full disk encryption on the host machine, probably on the VM, use
different passwords between the two, and keep the machine fully powered off when
not in immediate active use.</p>

<h2>Step 2: Take a Trip</h2>

<p><blockquote><p>Number 5: never sell no crack where you rest at<br/>I don't care if they want a ounce, tell 'em "bounce!"</p><footer><strong>Biggie Smalls</strong> <cite>Counterintelligence Theory and Practice for Crack Dealers</cite></footer></blockquote></p>

<p>Alice must ensure that every single time she contacts Bob, or checks for contact
from Bob, she is in a location which is not linked to her. Additionally, she must
use an internet connection which is not linked to her, for example a public WiFi
or a prepaid 3G card.</p>

<p>When Alice goes to contact Bob, she must ensure that she does not carry any device
which will transmit her physical location. For example, her mobile phone(s). Leave
it at home.</p>

<h2>Step 3: UnlinkedIn</h2>

<p>After Alice has used her dedicated machine to communicate with Bob, she should
revert the VM snapshot to the pristine state from right after she installed. This
should limit the ability of the adversary to persist after a compromise (provided
they didn't escape the VM).</p>

<p>The <em>converse-with-Bob</em> machine must be used with new accounts created specifically
for, and exclusively to, converse with Bob. These accounts must be created from
the new machine, and never be used for anything else except Bob related activity.
Alice must create new accounts that don't have any links to her real identity.
For email, one option is a <a href="http://www.tormail.net">TorMail</a> account. For instant
messaging there is either Cryptocat over Tor, or create a new Jabber
account such as with <a href="http://jabber.ccc.de">jabber.ccc.de</a>.</p>

<h2>Concluding Thoughts</h2>

<p>The core concept to take away here is: separate identity, with equipment and
accounts, used only for one activity. The essense of compartmentation is separation
without contamination. My strong recommendation is to use: a virgin machine, with
virgin accounts, to contact the target. This machine is used exclusively for this one
activity: it is <strong>compartmented</strong>. Associating the activity of that online entity,
even with full and complete global internet monitoring (and 0day attacks) with a
specific individual should be difficult. [<strong>NOTE:</strong> don't count on this if you
happen to be the new <em>al Quaida</em> #3].</p>
]]></content>
  </entry>
  
</feed>
